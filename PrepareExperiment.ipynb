{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31500680-74aa-4e96-a192-3080f06e8d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# full path to 30 FPS video\n",
    "seq_id = '2024_08_15__19_55_49'\n",
    "rgb_video_path = f\"/media/zipa/Data/egowalk_30FPS/egowalk_cosmos_processed/video/rgb/{seq_id}__rgb.mp4\"\n",
    "dpt_video_path = f\"/media/zipa/Data/egowalk_30FPS/egowalk_cosmos_processed/video/depth/{seq_id}__depth.mkv\"\n",
    "assert(os.path.exists(rgb_video_path))\n",
    "assert(os.path.exists(dpt_video_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17da8899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "def calc_initial_frame(src_video_path, h, m, s):\n",
    "    obj = cv2.VideoCapture(src_video_path)\n",
    "    fps = int(obj.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(obj.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(obj.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    return (h * 60 * 60 + m * 60 + s ) * fps, (fps, width, height)\n",
    "\n",
    "def load_video_fragment(src_video_path, initial_frame, frames_count, frames_step, drop_chans=False):\n",
    "    frames = []\n",
    "    rdr = cv2.VideoCapture(src_video_path)\n",
    "    # print(fps := rdr.get(cv2.CAP_PROP_FPS))\n",
    "    i_frame = 0\n",
    "    while True:\n",
    "        have_read, frame_data = rdr.read()\n",
    "        if not have_read:\n",
    "            break\n",
    "        if i_frame >= initial_frame and (i_frame - initial_frame) % frames_step == 0:\n",
    "            # print(f\"Pushing frame {i_frame}\")\n",
    "            if drop_chans:\n",
    "                frame_data = frame_data[:, :, 0]\n",
    "            frames.append(frame_data)\n",
    "            if len(frames) == frames_count:\n",
    "                break\n",
    "        i_frame += 1\n",
    "    assert(len(frames) == frames_count)\n",
    "    return frames\n",
    "\n",
    "def save_video(output_path, frames, fps):\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frames[0].shape[1], frames[0].shape[0]))\n",
    "    for frame in frames:\n",
    "        if len(frame.shape) == 2:\n",
    "            frame = np.stack([frame, frame, frame], axis=2)\n",
    "        out.write(frame)\n",
    "    out.release()\n",
    "\n",
    "def save_experiment(rgb, dpt, fps, prompt, is_full_prompt, experiment_folder, relative_root='./'):\n",
    "    rgb_name = f'{experiment_folder}/rgb.mp4'\n",
    "    dpt_name = f'{experiment_folder}/depth.mp4'\n",
    "    json_name = f'{experiment_folder}/spec.json'\n",
    "    shell_name = f'{experiment_folder}/runme.sh'\n",
    "\n",
    "    os.makedirs(os.path.join(relative_root, experiment_folder), 0o777, True)\n",
    "    save_video(os.path.join(relative_root, rgb_name), rgb, fps)\n",
    "    save_video(os.path.join(relative_root, dpt_name), dpt, fps)\n",
    "\n",
    "    with open(os.path.join(relative_root, json_name), 'w') as fp:\n",
    "        json.dump({\"prompt\": prompt, \"input_video_path\": rgb_name,\n",
    "                    \"depth\": {\"input_control\": dpt_name, \"control_weight\": 1.0},\n",
    "                    \"edge\": {\"control_weight\": 1.0},\n",
    "                    \"vis\": {\"control_weight\": 1.0},\n",
    "                    \"seg\": {\"control_weight\": 1.0}\n",
    "                    }, fp)\n",
    "\n",
    "    # generate script to call it from shell\n",
    "    shell_script_full_path = os.path.join(relative_root, shell_name)\n",
    "    output_string = \"\"\"\n",
    "    export CUDA_VISIBLE_DEVICES=\"${CUDA_VISIBLE_DEVICES:=0}\"\n",
    "    export CHECKPOINT_DIR=\"${CHECKPOINT_DIR:=./checkpoints}\"\n",
    "    export NUM_GPU=\"${NUM_GPU:=1}\"\n",
    "    \"\"\"\n",
    "\n",
    "    output_string += f\"PYTHONPATH=$(pwd) torchrun --nproc_per_node=$NUM_GPU --nnodes=1 --node_rank=0 cosmos_transfer1/diffusion/inference/transfer.py \\\n",
    "        --checkpoint_dir $CHECKPOINT_DIR \\\n",
    "        --video_save_folder {experiment_folder}/output \\\n",
    "        --controlnet_specs {json_name} \\\n",
    "        --offload_text_encoder_model \\\n",
    "        --offload_guardrail_models \\\n",
    "        --offload_prompt_upsampler \\\n",
    "        --num_gpus $NUM_GPU\"\n",
    "    if not is_full_prompt:\n",
    "        output_string += \" --upsample_prompt\" + '\\n'\n",
    "    else:\n",
    "        output_string += '\\n'\n",
    "    with open(shell_script_full_path, 'w') as fp:\n",
    "        print(output_string, file=fp)\n",
    "\n",
    "    os.chmod(shell_script_full_path, 0o777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf77d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_frame, _ = calc_initial_frame(rgb_video_path, h=0, m=2, s=0)\n",
    "rgb = load_video_fragment(rgb_video_path, starting_frame, 4 * 30, frames_step=1, drop_chans=False)\n",
    "dpt = load_video_fragment(dpt_video_path, starting_frame, 4 * 30, frames_step=1, drop_chans=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005b5789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "fig.set_size_inches(15, 5)\n",
    "for i_axis, data in enumerate([rgb[0], dpt[0]]):\n",
    "    axes[i_axis].imshow(data)\n",
    "    axes[i_axis].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a009e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full code for generating the experiment\n",
    "fps = 30\n",
    "# prompt = \"The video captures a series of frames showing a street view from a pedastrian. \\\n",
    "#     The street is lined with buildings of various colors, including red, yellow, and white. \\\n",
    "#     There are no visible pedestrians, and the traffic is minimal with a few cars and a motorcycle passing by. \\\n",
    "#     The sky is partly cloudy with blue patches, and the overall atmosphere appears calm.\"\n",
    "prompt = \"moving through city street. buildings around, few people ahead.\"\n",
    "\n",
    "is_full_prompt = False\n",
    "start_time_in_minutes = 2 # minutes\n",
    "fragment_length_in_seconds = 4 # seconds\n",
    "    \n",
    "starting_frame, _ = calc_initial_frame(rgb_video_path, h=0, m=start_time_in_minutes, s=0)\n",
    "\n",
    "experiment_folder = f'{seq_id}_{starting_frame}_{fps}_{fragment_length_in_seconds}_{\"full\" if is_full_prompt else \"short\"}' \n",
    "\n",
    "rgb = load_video_fragment(rgb_video_path, starting_frame, fragment_length_in_seconds * fps, frames_step=1, drop_chans=False)\n",
    "dpt = load_video_fragment(dpt_video_path, starting_frame, fragment_length_in_seconds * fps, frames_step=1, drop_chans=True)\n",
    "save_experiment(rgb, dpt, fps, prompt, is_full_prompt, experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81439955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate several experiments\n",
    "prompt = \"moving through city street. buildings around, few people ahead.\"\n",
    "is_full_prompt = False\n",
    "downsampling_resolution = 4\n",
    "fps_range = [4]#[4, 30]\n",
    "duration_range = [2]#[2, 4, 8]\n",
    "start_range = [0, 1, 2, 3]\n",
    "prefix = 'small'\n",
    "\n",
    "for fps in fps_range:\n",
    "    for fragment_length_in_seconds in duration_range:\n",
    "        for start_time_in_minutes in start_range:\n",
    "            starting_frame, _ = calc_initial_frame(rgb_video_path, h=0, m=start_time_in_minutes, s=0)\n",
    "            experiment_folder = prefix + f'{seq_id}_{starting_frame}_{fps}_{fragment_length_in_seconds}_{\"full\" if is_full_prompt else \"short\"}' \n",
    "            if fps == 30:\n",
    "                frames_step = 1\n",
    "            elif fps == 4:\n",
    "                frames_step = 7\n",
    "            rgb = load_video_fragment(rgb_video_path, starting_frame, fragment_length_in_seconds * fps, frames_step=frames_step, drop_chans=False)\n",
    "            dpt = load_video_fragment(dpt_video_path, starting_frame, fragment_length_in_seconds * fps, frames_step=frames_step, drop_chans=True)\n",
    "            if downsampling_resolution > 1:\n",
    "                for i_frame in range(len(rgb)):\n",
    "                    rgb[i_frame] = rgb[i_frame][::downsampling_resolution, ::downsampling_resolution, :]\n",
    "                    dpt[i_frame] = dpt[i_frame][::downsampling_resolution, ::downsampling_resolution]\n",
    "            save_experiment(rgb, dpt, fps, prompt, is_full_prompt, experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c510b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait for file to get ready on nabo\n",
    "import time\n",
    "while not os.path.exists('./small2024_08_15__19_55_49_18000_4_2_short/output/output.txt'):\n",
    "    os.system(\"sshpass -p 'megaB0SS' scp -r kzipa@10.16.84.42:/mnt/vol2_raid/shared_data/cosmos/cosmos-transfer1/small2024_08_15__19_55_49_18000_4_2_short ..\")\n",
    "    time.sleep(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295ced22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update prompts in follow-up\n",
    "frames = {0: 0, 1: 6000, 2: 12000, 3: 18000}\n",
    "prompts_from_files = {}\n",
    "for s in [0, 1, 2, 3]:\n",
    "    with open(f'./small2024_08_15__19_55_49_{frames[s]}_4_2_short/output/output.txt') as fp:\n",
    "        full_prompt = fp.read() \n",
    "    prompts_from_files[s] = full_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de290d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate full-resolution videos with long prompt, that we got using small-resolution, small-fps model with short prompts\n",
    "is_full_prompt = True\n",
    "start_to_prompt = {0: \"The video is taken from a first-person perspective, likely with a camera mounted on the person's head or chest. \\\n",
    "    The setting appears to be a city street with buildings on either side. \\\n",
    "    The sky is overcast, and the lighting is dim, suggesting it could be early morning or late afternoon. \\\n",
    "    The street is mostly empty, with a few pedestrians visible in the distance. \\\n",
    "    The buildings have a modern architectural style, with large windows and neutral-colored facades. \\\n",
    "    The person's hand is visible in the foreground, holding what appears to be a camera or phone.\",\n",
    "                   1: \"The video is taken from a first-person perspective, likely with a camera mounted on the person's head or chest. \\\n",
    "    The person is walking through a city street, with buildings on either side and a few pedestrians visible in the distance. \\\n",
    "    The sky is overcast, and the street appears to be relatively empty with no visible traffic. \\\n",
    "    The person's hands are visible in the foreground, and they are wearing a dark-colored jacket. \\\n",
    "    The video does not show any significant action or event, but rather a routine walk through an urban environment.\",\n",
    "                   2: \"The video is taken from a first-person perspective, likely with a camera mounted on the person's head or chest. \\\n",
    "    The environment is an urban street with buildings on either side, and the sky is visible at the top of the frame. \\\n",
    "    The street is paved, and there are a few pedestrians visible in the distance. \\\n",
    "    The color palette is dominated by the grays of the pavement and the buildings, with the sky showing a soft blue hue. \\\n",
    "    The pedestrians are too far to discern any specific details about them.\",\n",
    "                   3: \"The video is taken from a first-person perspective, likely with a camera mounted on the person's head or chest. \\\n",
    "    The scene is an urban environment with buildings on either side of the street. \\\n",
    "    The sky is overcast, and the lighting is dim, suggesting either early morning or late afternoon. \\\n",
    "    The street is relatively empty, with a few pedestrians visible in the distance. \\\n",
    "    The buildings have a classic architectural style with large windows and detailed facades. \\\n",
    "    The person in the video is wearing a dark-colored jacket and appears to be walking or standing still.\"\n",
    "}\n",
    "\n",
    "start_to_prompt = prompts_from_files\n",
    "\n",
    "downsampling_resolution = 1\n",
    "fps_range = [4, 30]\n",
    "duration_range = [2, 4, 8]\n",
    "start_range = [3] #[0, 1, 2, 3]\n",
    "prefix = ''\n",
    "\n",
    "experiment_folders = []\n",
    "for fps in fps_range:\n",
    "    for fragment_length_in_seconds in duration_range:\n",
    "        for start_time_in_minutes in start_range:\n",
    "            starting_frame, _ = calc_initial_frame(rgb_video_path, h=0, m=start_time_in_minutes, s=0)\n",
    "            experiment_folder = prefix + f'{seq_id}_{starting_frame}_{fps}_{fragment_length_in_seconds}_{\"full\" if is_full_prompt else \"short\"}' \n",
    "            if fps == 30:\n",
    "                frames_step = 1\n",
    "            elif fps == 4:\n",
    "                frames_step = 7\n",
    "            rgb = load_video_fragment(rgb_video_path, starting_frame, fragment_length_in_seconds * fps, frames_step=frames_step, drop_chans=False)\n",
    "            dpt = load_video_fragment(dpt_video_path, starting_frame, fragment_length_in_seconds * fps, frames_step=frames_step, drop_chans=True)\n",
    "            if downsampling_resolution > 1:\n",
    "                for i_frame in range(len(rgb)):\n",
    "                    rgb[i_frame] = rgb[i_frame][::downsampling_resolution, ::downsampling_resolution, :]\n",
    "                    dpt[i_frame] = dpt[i_frame][::downsampling_resolution, ::downsampling_resolution]\n",
    "            save_experiment(rgb, dpt, fps, start_to_prompt[start_time_in_minutes], is_full_prompt, experiment_folder)\n",
    "            # print shell instructions to paste them into command line\n",
    "            experiment_folders.append(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92029fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment_folder in experiment_folders:\n",
    "    command = f'sshpass -p \"megaB0SS\" scp -r ./{experiment_folder} kzipa@10.16.84.42:/mnt/vol2_raid/shared_data/cosmos/cosmos-transfer1'\n",
    "    print(command)\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e46a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folders1 += experiment_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9ad476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_composed_command(command_list, filter_word):\n",
    "    commands = []\n",
    "    for experiment_folder in command_list:\n",
    "        if filter_word in experiment_folder:\n",
    "            commands.append(f'./{experiment_folder}/runme.sh')\n",
    "    return ' && '.join(commands)\n",
    "\n",
    "# pass my commands to docker container\n",
    "for filter in ['_2_full', '_4_full', '_8_full']:\n",
    "    command = filtered_composed_command(experiment_folders1, filter)\n",
    "    print(command)\n",
    "    # print('Pending...')\n",
    "    # os.system(f\"sshpass -p megaB0SS ssh kzipa@10.16.84.42 'docker exec stoic_agnesi {command}'\")\n",
    "    # print('...done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae7bff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy everything on my local device\n",
    "for experiment_folder in experiment_folders1:\n",
    "    # command = f'sshpass -p \"megaB0SS\" scp -r kzipa@10.16.84.42:/mnt/vol2_raid/shared_data/cosmos/cosmos-transfer1/{experiment_folder}/output ./{experiment_folder}'\n",
    "    # print(command)\n",
    "    # os.system(command)\n",
    "    assert(os.path.exists(f'./{experiment_folder}/output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c336e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment_folder in experiment_folders1:\n",
    "    assert(os.path.exists(f'./{experiment_folder}/output'))\n",
    "    input_video = f'./{experiment_folder}/rgb.mp4'\n",
    "    output_video = f'./{experiment_folder}/output/output.mp4'\n",
    "    assert(os.path.exists(input_video))\n",
    "    assert(os.path.exists(output_video))\n",
    "    _, (fps1, w1, h1) = calc_initial_frame(input_video, 0, 0, 0)\n",
    "    _, (fps2, w2, h2) = calc_initial_frame(output_video, 0, 0, 0)\n",
    "    print(experiment_folder, (fps1, w1, h1), (fps2, w2, h2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ego_walk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
